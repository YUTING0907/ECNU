## super resolution高分辨率
简单来说，超分辨率方法分为三类：基于插值的方法，基于重建的方法和基于学习的方法（即深度学习方法）

传统方法中，基于插值的方法包括最近邻插值、双线性插值和双三次插值等，具有算法简单，处理速度快，但在诸如边缘、纹理等像素突变处的处理效果差，易出现锯齿和块效应；

基于重构的方法包括频域方法和空域方法，但无法很好的模拟现实场景；

本文将具体介绍深度学习图像超分辨率SR任务应先掌握的基本概念知识，然后介绍SR任务应该从哪方面入手，希望对SR能有个全局方向性的认识，能更好的把论文串起来。

### 一、SR定义
超分辨率SR的定义：将低分辨率的图像通过算法转换成高分辨率图像

SR分两种：
SISR：单图像超分辨率\
VSR：视频超分辨率

通常的超分辨率指SISR，即给定一个低分辨率（LR）图像，然后重建出一个精确的高分辨率（HR）图像。

### 二、SISR任务的概念性知识
### 2.1 SISR重建的方向
1. 力求恢复出真实可靠的细节部分，对细节要求苛刻。\
应用如：医学影像上的超分辨率重建，低分辨率摄像头人脸或者外形的恢复等。

2. 追求整体视觉效果，细节部位要求不高。\
应用如：低分辨率视频电视的恢复、相机模糊图像的恢复等。

### 2.2 SISR方法
有监督的超分方法和无监督的超分

#### 有监督方法
图像高分辨任务现有主流的方法还是基于监督的深度学习方法，通常数据集是SR图像或者SR-LR图像对，但是一般现实很少能收集到SR-LR对，所以主要还是SR数据集，对于只有SR数据集，会先用一定的方法生成LR数据。然后再基于网络模型生成的HR图像，与真实图像之间进行差异比较

虽然SR最流行的损失函数是逐像素均方误差(即像素损失)，但更强大的模型倾向于使用多个损失函数的组合

有监督方法的基础是LR-HR图像对，网络模型的结构多种多样，下面介绍四种常见的结构:

**a.pre-upsampling SR**\
因为直接学习低分辨率图像和高分辨率图像之间的映射过程会比较困难，Dong等人在SRCNN中首次使用了pre-upsampling SR结构，即先对低分辨率图像做上采样操作，使上采样后的图像尺寸与高分辨率相同，然后学习该上采样后的图像和高分辨率图像之间的映射关系，极大地降低了学习难度。但是，预先上采样通常会带来副作用（例如，噪声放大和模糊），并且由于大多数操作是在高维空间中执行的，因此时间和空间的成本比其他框架要高得多。

![](https://raw.githubusercontent.com/YUTING0907/PicGo/main/img20230806111934.png)

**b.Post-upsampling SR**\
为了提高计算效率并充分利用深度学习技术，研究人员提出在低维空间进行大多数的运算，在网络的末端再进行上采样操作。该做法的好处是，由于具有巨大计算成本的特征提取过程仅发生在低维空间中，大大降低了计算量和空间复杂度，该框架也已成为最主流的框架之一，在近年的模型中被广泛应用。

![](https://raw.githubusercontent.com/YUTING0907/PicGo/main/img20230806111955.png)

**c.Progressive upsampling SR**\
虽然Post-upsampling SR很大程度上降低了计算难度，但对于比例因子较大的情况（4倍、8倍超分），使用Post-upsampling SR方法有较大的学习难度。而且，对于不同比例因子，需要分别训练一个单独的SR网络模型，无法满足对多尺度SR的需求。Progressive upsampling SR 框架下的模型是基于级联的CNN结构，逐步重建高分辨率图像。在每一个阶段，图像被上采样到更高的分辨率，Laplacian金字塔SR网络（LapSRN）就采用了上述框架。通过将一个困难的任务分解为简单的任务，该框架下的模型大大降低了学习难度，特别是在大比例因子的情况下，能够达到较好的学习效果。然而，这类模型也存在着模型设计复杂、训练稳定性差等问题，需要更多的建模指导和更先进的训练策略。

![](https://raw.githubusercontent.com/YUTING0907/PicGo/main/img20230806112023.png)

**d.Iterative up-and-down Sampling SR**\
为了更好地捕捉LR-HR图像对之间的相互依赖关系，在SR中引入了一种高效的迭代过程，称为反投影。DBPN就是基于该结构的模型之一，它交替连接上采样层和下采样层，并使用所有中间过程来重建最终的HR。该框架下的模型可以更好地挖掘LR-HR图像对之间的深层关系，从而提供更高质量的重建结果。然而，反投影模块的设计标准仍然不清楚，由于该机制刚刚被引入到基于深度学习的SR中，具有很大的潜力，需要进一步探索。

![](https://raw.githubusercontent.com/YUTING0907/PicGo/main/img20230806112047.png)

#### 无监督的超分方法

现有的超分辨率研究主要集中在有监督学习上，即利用匹配的LR-HR图像对进行学习。然而，由于同一场景不同分辨率的图像难以采集，因此通常通过对HR图像进行预先降质处理来获得SR数据集中的LR图像。为了学习真实世界的LR-HR映射，研究者们越来越关注无监督SR，在这种情况下，只提供未配对的LR-HR图像进行训练，从而使生成的模型更有可能处理真实场景中的SR问题。

考虑到单个图像内部的图像统计信息，Shocher等人提出了ZSSR，既不需要先验的图像样本也不需要先验的训练，它利用单张图片的内部重复信息在测试期间训练一个小型针对特定图片的CNN。具体地说，从单个图像估计退化内核，并使用该内核通过对该图像执行不同比例因子的降级和增强来构建一个小数据集，然后在这个数据集上训练一个小的用于SR的CNN并用于最终的预测。

另外还有这篇是CVPR2020中的一篇无监督超分文章，数据集为非配对的LR、HR，同时加入了CycleGAN的思想。
Unparied Image Super-Resolution Using Pseudo-Supervision。

### 2.3 上采样方法
基于插值(Interpolation-Based)的上采样方法：最近邻插值法、双线性插值法、双三次插值法
此类上采样方法只根据图像本身的信号来提高图像的分辨率，而没有带来更多的信息。

基于学习的上采样方法：转置卷积、亚像素卷积和元升级模块

**转置卷积**\
原理如图所示：
![](https://raw.githubusercontent.com/YUTING0907/PicGo/main/img20230806113607.png)

操作分为两步，首先对输入图像进行插值（零）使图像尺寸放大，然后对放大后的图像进行卷积操作。以上图为例，输入图像尺寸为3x3，对图像进行补零操作后，尺寸变为6x6，对该图像进行卷积处理，就能得到尺寸为6x6的目标图像，也就实现了二倍上采样。
转置卷积的缺点是容易产生棋盘格现象。

**亚像素卷积**\
亚像素卷积的原理如图所示:
![](https://raw.githubusercontent.com/YUTING0907/PicGo/main/img20230806113731.png)

首先对输入图像做卷积处理，生成sxs个特征图（s为上采样因子），然后对sxs个特征图做reshape操作，得到目标图像。（reshape方法如图）

假设输入尺寸为h*w*c，输出尺寸为h*w*s^2*c。之后执行整形操作( a.k.a.shuffle)产生尺寸为sh*sw*c的输出(图c)。在这种情况下，感受野可达3X3。由于端到端的上采样方式，该层也被SR模型广泛使用。与转置卷积层相比，亚像素层具有更大的感受野

**Meta Upscale Module**\
![](https://raw.githubusercontent.com/YUTING0907/PicGo/main/img20230806114853.png)

以往的方法需要预先定义缩放因子，即针对不同的因子训练不同的上采样模块，效率低下且不符合现实需求。因此，Hu等人提出了元升尺度模块(如图6所示)，该模块首先基于元学习解决任意尺度因子的SR问题。
具体来说，对于HR图像上的每个目标位置，该模块将其投影到LR featuremaps(即k k cin)上的一个小补丁上，通过密集层根据投影偏移量和缩放因子预测卷积权重(即k k cin cout)并进行卷积。通过这种方式，元升级模块可以通过单个模型以任意因子对其进行连续缩放。并且由于(多个因子同时训练)的训练数据量较大，该模块在固定因子上可以表现出相当甚至更好的性能。虽然该模块在推理时需要预测权重，但是上采样模块的执行时间只占特征提取时间的1%左右。然而，该方法基于若干个与图像内容无关的值来预测每个目标像素的大量卷积权重，因此当面临较大的放大倍数时，预测结果可能不稳定且效率较低。

### 2.4 SISR的过程步骤
基于深度学习超分辨率的起源：SRCNN(ECCV2014)

SRCNN文章于2014年提出，是第一篇将深度卷积神经网络（CNN）引入SR领域。\
作者只使用了三个卷积层，卷积核的大小分为为9x9,1x1和5x5。\
这三个卷积层也为SISR过程定义了三个步骤（后续的SISR文章都是基于这三个步骤的改进）：

* 1.LR特征提取（Patch extraction and representation），这个阶段主要是对LR进行特征提取，并将其特征表征为一些feature maps，通常称为浅层特征提取；

* 2.特征的非线性映射（Non-linear mapping），这个阶段主要是将第一阶段提取的特征映射至HR所需的feature maps；
  这部分主要用三篇论文（[VDSR](https://github.com/YUTING0907/ECNU/blob/main/HR/VDSR.md)，[EDSR](https://github.com/YUTING0907/ECNU/blob/main/HR/EDSR.md)，
[WDSR](https://github.com/YUTING0907/ECNU/blob/main/HR/WDSR.md)
)来讲解。

* 3.HR重建（Reconstruction），这个阶段是将第二阶段映射后的特征使用上采样方法恢复为HR图像。
既2016年的VDSR后，超分辨率SR的重建大部分使用ESPCN论文中提出的pixel-shuffle\
pixel-shuffle操作其实就是将H * W * C * r * r  ==>  rH * rW * C 
分辨遍历每一个通道将r与H、W混合（shuffle），即H * W 放大为 rH * rW，将照片从原来的大小放大为r倍。

```
在pytorch中：官方提供了pixel shuffle方法：
CLASS torch.nn.PixelShuffle(upscale_factor)
```

### 三、基于深度学习SISR网络的构建
上面介绍了SR的背景信息和概念知识，以下介绍SR的网络设计。

![](https://raw.githubusercontent.com/YUTING0907/PicGo/main/img20230806115040.png)

#### 1.Residual Learning残差学习
分为全局残差学习和局部残差学习两种。

全局残差学习
由于图像SR是一种图像到图像的转换任务，其中输入图像与目标图像高度相关，因此我们可以只学习它们之间的残差，这就是全局残差学习。在这种情况下，可以避免学习从一个完整图像到另一个图像的复杂变换，而只需要学习一个残差图来恢复丢失的高频细节。由于大部分区域的残差接近于零，模型的复杂度和学习难度大大降低。

局部残差学习
类似于ResNet中的残差学习，shortcut连接可以用于缓解网络深度不断增加所带来的模型退化问题，降低了训练难度，被广泛应用在超分任务中。

e.g. SRCNN、VDSR

#### 2.Recursive Learning递归学习
为了在不引入过多参数的情况下学习到更高级的特征，递归学习（即以递归方式多次应用相同模块）被应用到超分任务中，如上图(b)所示

一般来说，递归学习确实可以在不引入过多参数的情况下学习更精细的特征，但仍然无法避免较高的计算成本。它固有地带来了梯度问题的消失或爆炸问题，因此一些技术，如残差学习和多重监督经常与递归学习相结合，以缓解这些问题。
（e.g. DRCNN、MemNet、CARN、DSRN）

#### 3.Multi-Path Learning多路径学习
多路径学习是指通过多条路径传递特征，每条路径执行不同的操作，将它们的操作结果融合以提供更好的建模能力。具体来说，它可以分为全局、局部和特定规模的多路径学习。

全局多路径学习

是指利用多条路径来提取图像不同方面的特征，这些路径在传播过程中可以相互交叉，从而大大提高学习能力。（e.g. LapSRN、DSRN）

局部多路径学习

模块结构如下图所示，在该模块中，采用核尺寸为3×3和5×5的两个卷积层同时提取特征，然后将输出串接并再次进行相同的运算，最后再进行1×1的卷积运算。通过这种局部多路径学习，SR模型可以更好地从多尺度中提取图像特征，进一步提高性能。
（e.g. MSRN）

特定尺度的多路径学习

考虑到不同尺度的SR模型需要经过相似的特征提取，Lim等人提出了尺度特定的多路径学习方法来实现单网络的多尺度重建。具体地说，它们共享模型的主要组件（即用于特征提取的网络层），并分别在网络的开始和结束处附加特定比例的预处理结构和上采样结构（如图所示）。在训练期间，仅启用和更新与选定比例相对应的模块。这样，所提出的MDSR通过共享不同尺度下的大部分参数，大大减小了模型的规模，并表现出与单尺度模型相当的性能。CARN和ProSR也采用了类似的特定尺度的多路径学习。

### 4.Dense Connections稠密连接
自从Huang等人提出基于稠密块的DenseNet以来，稠密连接在视觉任务中的应用越来越广泛。对于稠密块体中的每一层，将所有前一层的特征图作为输入，并将其自身的特征图作为输入传递到所有后续层。稠密连接不仅有助于减轻梯度消失、增强信号传播和鼓励特征重用，而且还通过采用小增长率（即密集块中的信道数）和在连接所有输入特征映射后压缩通道数来显著减小模型尺寸。

### 5.Attention Mechanism注意力机制
考虑到不同通道之间特征的相互依赖关系，Hu等人提出了SENet，通过考虑通道之间的相互依赖关系来提高网络的学习能力。在该模块中，使用全局平均池化（GAP）将每个输入信道压缩成一个通道描述符（即常数），然后将这些描述符输入到两个密集层中，以产生各通道的权重因子。最近，Zhang等人将通道注意机制应用在超分中，提出了RCAN，显著提高了模型的表达能力。为了更好地探究特征之间的相关性，Dai等人进一步提出二阶通道注意力（SOCA）模块。SOCA通过使用二阶特征统计量代替了全局平均池化，以提取更加精细的特征。

### 6.Advanced Convolution高级卷积
由于卷积运算是深层神经网络的基础，研究人员也试图改进卷积运算以获得更好的性能或更高的效率。包括使用扩张卷积（空洞卷积）、分组卷积、深度可分离卷积等。

### 7.Region-Recursive Learning区域递归学习
大多数SR模型将SR视为与像素无关的任务，因此无法正确地生成像素之间的相互依赖关系。像素递归学习来执行逐像素生成，通过使用两个网络分别捕获全局上下文信息和串行生成依赖。通过使用一个循环的策略网络来依次发现被关注的补丁并进行局部增强。这样，它能够根据每幅图像的自身特点，自适应地为每幅图像个性化一条最优的搜索路径，从而充分挖掘图像的全局内部相关性

### 8.Pyramid Pooling金字塔池化
金字塔池化模块以更好地利用全局和局部上下文信息。具体来说，对于大小为h w c的特征图，将每个特征图划分为M M个bin，并进行全局平均池化，得到M M c个输出。然后进行1 1卷积，将输出压缩到单通道。然后，通过双线性插值将低维特征图上采样到与原始特征图相同的大小。通过使用不同的M，该模块有效地整合了全局和局部上下文信息。

### 9.Wavelet Transformation小波变换
通过将图像信号分解为表示纹理细节的高频子带和包含全局拓扑信息的低频子带，是一种高效的图像表示方法。Bae等首先将小波变换与基于深度学习的随机共振模型相结合，以插值LR子波的子带作为输入，预测相应HR子带的残差。WT和逆WT分别用于分解LR输入和重构HR输出

### 10.Desubpixel去亚像素
为了加快推理速度，去亚像素操作将图像在空间上进行分割，将其堆叠为额外的通道，从而避免信息的丢失。通过这种方式，在模型开始时对输入图像进行去亚像素降采样，在较低维空间中学习表示，并在最后上采样到目标大小。

### 11.xUnit
为了结合空间特征处理和非线性激活来更有效地学习复杂特征，ReLU被视为确定一个权重图来与输入进行逐元素相乘，而xUnit通过卷积和高斯门直接学习权重图。虽然xUnit对计算要求较高，但由于其对性能的影响较大，在与ReLU进行性能匹配的同时，可以极大地减小模型规模。通过这种方式，作者在不降低性能的情况下，将模型大小减少了近50%。

![](https://raw.githubusercontent.com/YUTING0907/PicGo/main/img20230806122439.png)

* 基于卷积神经网络的方法\
1.SRCNN(2016)：第一个SR深度学习网络，Image Super-Resolution Using Deep Convolutional Networks\
2.VDSR(2016)：首次提出利用残差深度网络解决SR问题\
3.ESPCN(2016)：基于像素重排列，不需要对LR进行上采样，使用卷积的方式逐步恢复至目标分辨率大小\
3.DRCNN\
4.HAN(2016)：整体注意力网络(holistic attention network) ，考虑到了多尺度层之间的相互依赖关系，以及各层特征的通道和空间相关性，帮助网络捕获更多的信息特征\
5.EDSR/MDSR(2017)：增强的深度超分辨率(enhanced deep super-resolution，EDSR)网络\
6.RCAN(2018)：首个将注意力机制应用于SR问题的网络\
7.MSRN(2018)：多尺度残差网络 (multi-scaleresidualnetwork，MSRN)，该方法在残差块上进行改进，并加入了多尺度大小的卷积核， 实现了不同尺度图像特征的自适应地检测\
8.MSFFRN(2020)：多尺度特征融合残差模块(multi-scale feature fusion residual block，MSFFRB)，通过多个交织路 径充分利用不同尺度下的浅层和深层局部图像特征信息\
9.MSFIN(2021)：轻量级的方法，就如何让复杂的SR算法迁移至移动设备进行了研究。

* 基于GAN的方法\
当缩放因子较大时，重建的SR图像由于缩放因子较大而缺乏纹理细节，重建效果并不理想。而 GAN 具有强大的生成力，可以很好地解决该问题。\
1.SRGAN(2016)\
2.USISResNet(2020)：一种无监督的超分算法\
3.BSRGAN(2021)

* 基于自注意力transformer的方法

### 四、几类损失函数
* 1.Pixel Loss像素损失函数
  像素损失衡量两幅图像之间的像素级差异，主要包括L1损失(即,平均绝对误差)和L2损失(即,均方误差)
* 2.Content Loss内容损失函数
  为了提升感知质量，利用神经网络中的生成的图像特征与真实图像特征之间的距离来进行计算，内容损失表示为两幅图像高层表示之间的欧氏距离
* 3.Adversarial Loss对抗损失函数
  得到的生成器可以产生与真实数据分布一致的输出，而判别器无法区分生成数据和真实数据。
* 4.Cycle Consistency Loss感知损失函数
  在 SRGAN 中将感知函数定义成内容损失和对抗损失的加权和
* 5.Total Variation Loss总变种损失
* 6.Prior-Based Loss基于先验的损失

### 五、学习策略
* Batch Normalization不适合SISR任务\
* Curriculum learning
  课程学习是指从较容易的任务开始，逐渐增加难度。由于超分辨率是一个不适定问题，并且总是遭受诸如大缩放因子、噪声和模糊等不利条件，为了降低学习难度，纳入了课程训练。为了降低大比例因子SR的难度，ProSR、ADRSR和Progressive CARN，不仅在架构上是渐进的，而且在训练过程上也是渐进的。训练从2次上采样开始，训练结束后，具有4个或更大比例因子的部分被逐步挂载并与之前的部分混合。
* Multi-Supervision多元监督
多监督是指在模型内部加入多个监督信号以增强梯度传播和避免消失和爆炸梯度

### 六、评价指标
PSNR： Peak Signal-to-Noise Ratio，峰值信噪比。PSNR数值越高，代表图像质量越好。

SSIM：结构相似性评价，Structural Similarity。SSIM是衡量两幅图像相似度的指标，其取值范围为[0,1]，SSIM的值越大，表示图像失真程度越小，说明图像质量越好。
意见平均分MOS（主观方法）：通过邀请接受过训练的普通人以及未接受过训练的普通人来对重建的图像进行评分，并且两者人数大致均衡。通过给重建图像打分，再对最后的得分进行平均，在视觉感知方面远远优于其它评价指标，可以准确测量图像感知质量。

### 七、数据集
* NTIRE Challenge
  CVPR(IEEE Conference on Computer Vision and Pattern Recognition)是世界顶级的计算机视觉会议（三大顶会之一，即IEEE国际计算机视觉与模式识别会议，另外两个是ICCV和ECCV）。
  CVPR下NTIRE（New Trends in Image Restoration and Enhancement Challenges）比赛，主要涉及图像超分辨率、图像去噪、去模糊、去摩尔纹、重建、去雾。本文主要基于NTIRE的超分辨率方面来谈，且只到2018年为止，更新的方法亲自行查阅资料。

  NTIRE主要有三个方向：图像超分辨率（super-resolution）、图像去雾（dehazing）、光谱重建（spectral reconstruction）。
  在超分辨率上有四个赛道：使用经典的bicubic（双三次插值）降尺度方式作为待重建图像，进行8倍放大重建。这也是目前大部分文献中最常见的设置方式之一。而其余三个赛道均是来自不同程度（Mild、Difficult、Wild）未知退化算子模拟相机采集的待重建图像（目的是模拟现实的图像），进行4倍放大重建。
  NTIRE2018比赛使用的数据集为DIV2K数据集，一共包含1000张2K分辨率的RGB图像，其中800张为训练集，100张为验证集，100张为测试集。评价标准使用了PSNR、SSIM。PSNR，即峰值信噪比，可以比较SR结果图和ground truth(即原高清大图)之间的差距；SSIM，即结构相似性，可以评价SR的恢复效果，更注重细节恢复。

* PIRM Challenge
  PIRM挑战是ECCV下的，其中一个子挑战关注轻量级能运用在smartphone上的研究和HR图像生成的准确率和质量
  
* DIV2K数据集下载地址：
官方：https://data.vision.ee.ethz.ch/cvl/DIV2K/

* 一般超分辨率文章使用的5个测试集Set5 , Set14, BSDS100, Urban100 and Manga109下载地址：original test datasets (HR images)
![](https://raw.githubusercontent.com/YUTING0907/PicGo/main/img20230805165034.png)

### 八、未来发展
1.Network Design
**Combining Local and Global Information结合局部和全局信息**\
大的感受野提供了更多的情境信息，有助于产生更真实的结果。因此，结合局部和全局信息为图像SR提供不同尺度的上下文信息是很有前途的。

**Combining Low-and High-Level Information结合低层和高层信息**\
卷积神经网络中的Hallow层倾向于提取颜色和边缘等低层特征，而更深的层学习更高层的表示，就像物体身份一样。因此，将低层细节与高层语义相结合可以对HR重建有很大的帮助。

**Context-Specific Attention情境特异性注意**\
在不同的语境中，人们往往会关注图像的不同方面。例如，在草地区域，人们可能更关心局部的颜色和纹理，而在动物身体区域，人们可能更关心物种和相应的毛发细节。因此，融入注意力机制，增强对关键特征的关注，有利于逼真细节的生成。

**More Efficient Architectures更高效的架构**\
现有的SR模型往往追求性能的极致，而忽略了模型的规模和推理速度。例如，在DIV2K上使用Titan GTX GPU 实现的EDSR每幅图像4个SR耗时20s，DBPN每幅图像8个SR耗时35s。如此长的预测时间在实际应用中是不可接受的，因此更高效的架构势在必行。如何在保持性能的同时，减少模型规模，加快预测速度仍然是一个难题。

**Upsampling Methods上采样方法**
现有的上采样方法都存在或多或少的缺点：插值法导致昂贵的计算且无法端到端学习，转置卷积产生棋盘格伪影，亚像素层带来感受野分布不均匀，元上标模块可能导致不稳定或效率低下且有进一步改进的空间。
如何进行有效且高效的上采样仍然需要研究，特别是在高缩放因子的情况下。近年来，用于深度学习的神经架构搜索( Neural Architecture Search，NAS )技术越来越受欢迎，在很少人工干预的情况下极大地提高了性能。对于SR领域，将上述方向的探索与NAS相结合具有很大的潜力。

2.Learning Strategies
Loss Functions现有的损失函数可以看作是在LR / HR / SR图像之间建立约束，并根据是否满足这些约束来指导优化。在实际应用中，这些损失函数往往是加权组合的，SR的最佳损失函数仍不清楚。因此，探索这些图像之间的潜在相关性并寻求更精确的损失函数是最有前景的方向之一

Normalization尽管BN被广泛应用于视觉任务中，极大地加快了训练速度，提高了性能，但它被证明是次优的超分辨率。因此，需要研究其他有效的SR归一化技术。

3.Evaluation Metrics
PSNR和SSIM是目前应用最广泛的SR评价指标。然而，PSNR容易导致过度平滑，并且在几乎无法区分的图像之间，结果可能会有很大的差异。SSIM从亮度、对比度和结构等方面进行评价，但仍不能准确衡量感知质量。此外，MOS是最接近人类视觉反应的，但需要花费大量的精力且不可复制。尽管研究者们提出了各种度量指标，但目前还没有一个统一的、公认的SR质量评价指标。因此，迫切需要更准确的评价重建质量的指标。

Blind IQA Methods
目前用于SR的大多数指标都是全参考方法，即假设我们有一对质量完美的LR-HR图像。但由于这类数据集较难获取，常用的评估数据集往往通过人工退化的方式进行。在这种情况下，我们进行评估的任务实际上是预定义退化的逆过程。因此，发展Blind IQA方法也具有很大的需求。

4.Unsupervised Super-Resolution
采集同一场景不同分辨率的图像往往比较困难，因此双三次插值被广泛用于构建SR数据集。然而，在这些数据集上训练的SR模型可能只学习预定义退化的逆过程。因此，如何进行无监督的超分辨率(即在没有配对LR-HR的数据集上进行训练)是未来发展的一个很有前景的方向。

5.Towards Real-World Scenarios
图像超分辨率在实际场景中受到很大的限制，例如遭受未知的降质，丢失配对的LR - HR图像。真实世界的图像往往会出现模糊、加性噪声和压缩伪影等退化现象。因此，在人工构建的数据集上训练的模型在真实场景中往往表现不佳。为了解决这个问题，已经提出了一些工作，但是这些方法存在一些固有的缺陷，例如训练难度大，假设条件过于完善。这一问题亟待解决。特定领域的应用。超分辨率不仅可以直接用于特定领域的数据和场景，而且对其他视觉任务也有很大的帮。因此，将SR应用于更具体的领域，如视频监控、目标跟踪、医学成像和场景渲染等，也是一个很有前景的方向。

参考：
paper：Deep Learning for Image Super-Resolution: A Survey
https://zhuanlan.zhihu.com/p/276027388
