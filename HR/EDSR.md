## EDSR
### Abstract
发表在CVPR2017， 
增强型深度残差网络EDSR，是NTIRE2017超分辨率挑战赛上获得冠军的方案。

github(torch): https://github.com/LimBee/NTIRE2017 \
github(tensorflow): https://github.com/jmiller656/EDSR-Tensorflow \
github(pytorch): https://github.com/thstkdgus35/EDSR-PyTorch

1.作者推出了一种加强版本的基于Resnet块的超分方法--EDSR，它实际上是在SRResnet上的改进，移除了不适合SR任务的BN块，从而在节省下来的空间下扩展模型的size来增强表现力，其取得了当时SOAT的水平。

2.此外，作者在文中还介绍了一种基于EDSR的多缩放尺度融合在一起的新结构——MDSR,包括×2、3、4。相比训练3个不同单一尺度的SR网络，MDSR可以节省更多的参数。

3.为了减缓feature map过多(滤波器过多或者说通道数过大)带来训练不稳定的问题，作者借用Inception-ResNet那篇文章说的residual scaling技术加入到EDSR的残差块最后一层CNN后

4.此外，作者通过实验证明使用L1−Loss比L2−Loss具有更好的收敛特性。

### 一、Introduction
近几年来，深度学习在SR领域展现了较好的图像高分辨率重建表现，但是网络的结构上仍然存在着一些待优化的地方：

* 1.深受神经网络的影响，SR网络在超参数(Hyper-parameters)、网络结构(Architecture)十分敏感。

* 2.之前的算法(除了VDSR)总是为特定up-scale-factor而设计的SR网络，即scale-specific，将不同缩放尺度看成是互相独立的问题，因此我们需要一个统一的网络来处理不同缩放尺度的SR问题，比如×2,3,4，这比训练3个不同缩放尺度的网络节省更多的资源消耗。

❤️针对第一个网络结构问题，作者在SRResNet的基础上，对其网络中多余的BN层进行删除，从而节约了BN本身带来的存储消耗以及计算资源的消耗，相当于简化了网络结构。
此外，选择一个合适的loss function，作者经过实验证明L1-Loss比L2-Loss具有更好的收敛特性。
MSE就是典型的L2-Loss

❤️针对第二个多缩放尺度问题，作者用2种不同的方式去处理：
* 1.使用低缩放尺度(×2)训练之后的模型作为高缩放尺度的初始化参数，结果取得很好的表现，说明不同尺度之间是有内在相关联系的。

* 2.作者设计以了一个可以结合多尺度的SR网络MDSR，除了网络的头部和尾部为各个缩放尺度独立之外，中间部分是共享网络。这种多尺度SR网络具有和单一缩放网络相近的表现力，且相比n个单一网络，n个尺度相结合的MDSR消耗更少的资源。

EDSR和MDSR将在标准测试数据集上做测试，分别是Set5、Set14、B100、Urban100以及新的数据集DIV2K。结果显示两种算法在PSNR/SSIM上都取得了SOAT的表现，并在NTIRE2017超分大赛上包揽冠亚军。


### 二、Proposed Methods
本节将正式开始介绍一种增强版本的SRResNet——EDSR(一种single-scale网络)，
它通过移除了适合分类这种高级计算机视觉任务而不适合SR这种低级计算机视觉任务的BN层来减少计算资源损耗。\
除此之外，本节还会介绍一种集合了多尺度于一个网络中的multi-scale超分网络——MDSR。

#### 2.1 Residual blocks
![](https://raw.githubusercontent.com/YUTING0907/PicGo/main/img20230730153702.png)

**BN的介绍：**
Batch Norm可谓深度学习中非常重要的技术，不仅可以使训练更深的网络变容易，加速收敛，还有一定正则化的效果，可以防止模型过拟合。在很多基于CNN的分类任务中，被大量使用。

但在图像超分辨率和图像生成方面，BatchNorm的表现并不是很好。当这些任务中，网络加入了BatchNorm层，反而使得训练速度缓慢且不稳定，甚至最后结果发散。

**图像超分辨率不适宜用BN的原因：**
在超分辨率任务中，过拟合并不常见。比如dropout或者L2正则都很少被采用，因此如果在训练并不存在困难的基础上，BN并不能提供对超分辨率任务有效的辅助作用。

对于SR来说给定输入低分辨率图像，输出高分辨率图像，中间过程学习的是细节信息。其输入输出的分布基本一致，加入BN后，BN白化中间的特征的方式完全破坏了原始空间的表征，即使input和output的数据分布发生了变化，而在重建时，BN还要拿出一部分参数做这部分的恢复。有研究人员在训练中尝试加入BN，研究其工作日志发现加入BN的网络loss的收敛速度明显比没有BN的要慢很多且loss的波动会非常大。因此，加入BN增加了内存和计算负担不如直接去掉。

更通俗一点来说，图像超分辨率网络输出的图像在色彩、对比度、亮度上要求和输入一致，改变的仅仅是分辨率和一些细节，而Batch Norm，对图像来说类似于一种对比度的拉伸，任何图像经过Batch Norm后，其色彩的分布都会被归一化，也就是说，它破坏了图像原本的对比度信息，所以Batch Norm的加入反而影响了网络输出的质量。虽然Batch Norm中的scale和shift参数可以抵消归一化的效果，但这样就增加了训练的难度和时间，还不如直接不用。

另外，BN是把数据归一化到[0,1]之间，算出每批图片的均值和方差，然后每张图片减去批得到的均值再除以方差，而超分辨率任务是一个回归任务，每个batch并没有太多的相关性，这就使得超分辨率任务在在各个batch中呈现的均值和方差很难进行稳定统计。

#### 2.2 Single-scale model
EDSR是SRResNet的增强版本，是一种基于上图红框所示的残差块。
![](https://raw.githubusercontent.com/YUTING0907/PicGo/main/img20230730154547.png)

如上图所示就是EDSR的结构：最上面一排是网络结构，可以大致分为低层特征信息提取、高层特征信息提取、反卷积(上采样)层、重建层，基本和SRResNet、SRDenseNet是类似的。下面第二层分别表示残差块的构造以及反卷积层(分别是×2、×3、×4)的构造。

Note:
* 1.连接①是将不同level的特征信息进行合并；连接②是ResNet块内部的残差连接。\
* 2.在EDSR的baseline中，是没有residual scaling的，因为只是用到了64层feature map，相对通道数较低，几乎没有不稳定现象。但是在最后实验的EDSR中，作者是设置了residual scaling中的缩减系数为0.1，且B=32,F=256。

  增加模型表现力最直接的方式就是增加模型的参数(复杂度)，一般可以通过增加模型层数B(即网络深度)以及滤波器个数F(即网络宽度或者说通道数)。此外两者对于存储资源的消耗大约是O(BF)，增加的参数大约是O(BF^2)，因此增加滤波器个数才能在有限存储空间下最大化参数个数。

在Inception-ResNet这篇文章以及本文中都指出，过大的滤波器个数(feature map个数，或者说通道数)会导致网络不稳定，最佳的解决办法不是降低学习率或者增加BN层，而是通过在残差块最后一层卷积后加上Residual scaling层：


#### 2.3 Multi-scale model
![](https://raw.githubusercontent.com/YUTING0907/PicGo/main/img20230730155501.png)

上图蓝色线表示的用训练好的up-scale-factor=2的EDSR网络作为×3,4训练时候的初始化参数，结果来看收敛速度以及表现力的提升都是有目共睹的，这一定程度上说明了不同缩放尺度之间是存在某种内在联系的。

因此作者设计了一种在单一网络中实现多尺度融合的SR网络——MDSR，其结构如下:
![](https://raw.githubusercontent.com/YUTING0907/PicGo/main/img20230730155552.png)

如上图所示是MDSR的网络结构，每个预处理模块由2个5×5的卷积层组成，针对每一种up-scale-factor设置不同的残差块；中间是一个共享残差网络；尾巴处是针对不同缩放倍数设计的上采样网








  
